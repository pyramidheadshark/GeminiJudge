# geminijudge/app.py
import streamlit as st
from dotenv import load_dotenv
import os

import prompts
import gemini_utils

load_dotenv()

def initialize_session_state():
    defaults = {
        "api_key_input": os.getenv("GOOGLE_API_KEY", ""),
        "gemini_configured": False,
        "uploaded_st_files": [],
        "processed_gemini_files": [],
        "user_prompt_input": "",
        "model_a_response_input": "",
        "num_incorrect_samples_input": 2, # –£–º–µ–Ω—å—à–∏–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, —Ç.–∫. –æ—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–µ–µ
        "generated_incorrect_responses": [],
        "evaluation_result_id": None,
        "evaluation_rationale": "", # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
        "all_responses_for_evaluation": {},
        "log_messages": [],
        "app_run_id": 0,
        "processing_complete": False
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value
    
    if st.session_state.api_key_input and not st.session_state.gemini_configured:
        gemini_utils.configure_gemini_api()

initialize_session_state()

# --- –õ–æ–≥–∏–∫–∞ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---
def handle_file_uploads_and_processing(uploaded_st_files_list: list) -> bool:
    st.session_state.processed_gemini_files = []
    if not uploaded_st_files_list:
        gemini_utils.log_info("–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã.")
        return True
    all_successful = True
    for i, st_file in enumerate(uploaded_st_files_list):
        gemini_utils.log_info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ {i+1}/{len(uploaded_st_files_list)}: {st_file.name}")
        gemini_file_obj = gemini_utils.upload_file_to_gemini(st_file, display_name_prefix=f"doc{i+1}")
        if gemini_file_obj and hasattr(gemini_file_obj, 'state') and gemini_file_obj.state.name == "ACTIVE":
            st.session_state.processed_gemini_files.append(gemini_file_obj)
        elif gemini_file_obj:
            gemini_utils.log_warning(f"–§–∞–π–ª {st_file.name} –∑–∞–≥—Ä—É–∂–µ–Ω, –Ω–æ –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω (—Å–æ—Å—Ç–æ—è–Ω–∏–µ: {gemini_file_obj.state.name}).")
            all_successful = False 
        else:
            gemini_utils.log_error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª {st_file.name}.")
            all_successful = False
    if all_successful and st.session_state.processed_gemini_files:
        gemini_utils.log_success(f"{len(st.session_state.processed_gemini_files)} —Ñ–∞–π–ª–æ–≤ —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã.")
    elif st.session_state.processed_gemini_files:
         gemini_utils.log_warning(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(st.session_state.processed_gemini_files)} –∏–∑ {len(uploaded_st_files_list)} —Ñ–∞–π–ª–æ–≤.")
    elif uploaded_st_files_list:
        gemini_utils.log_error("–ù–∏ –æ–¥–∏–Ω –∏–∑ —Ñ–∞–π–ª–æ–≤ –Ω–µ –±—ã–ª —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω.")
        all_successful = False
    return all_successful

def generate_and_parse_incorrect_responses_logic(user_prompt: str, model_a_response: str, num_samples: int) -> bool:
    st.session_state.generated_incorrect_responses = []
    prompt_text = prompts.get_generate_incorrect_answers_prompt(user_prompt, model_a_response, num_samples)
    
    raw_response = gemini_utils.generate_text_from_model(
        prompt_text, model_type="generation", # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        files_for_context=st.session_state.processed_gemini_files
    )
    if not raw_response:
        gemini_utils.log_error("–ù–µ –ø–æ–ª—É—á–µ–Ω—ã '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ' –æ—Ç–≤–µ—Ç—ã –æ—Ç –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.")
        return False

    parsed_responses = []
    current_answer_accumulator = []
    for line in raw_response.splitlines():
        if line.startswith(prompts.INCORRECT_ANSWER_PARSING_PREFIX):
            if current_answer_accumulator:
                parsed_responses.append("\n".join(current_answer_accumulator).strip())
            current_answer_accumulator = [line.replace(prompts.INCORRECT_ANSWER_PARSING_PREFIX, "", 1).strip()]
        elif current_answer_accumulator:
            current_answer_accumulator.append(line.strip())
    if current_answer_accumulator:
        parsed_responses.append("\n".join(current_answer_accumulator).strip())
    st.session_state.generated_incorrect_responses = [resp for resp in parsed_responses if resp]

    if not st.session_state.generated_incorrect_responses:
        gemini_utils.log_warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ' –æ—Ç–≤–µ—Ç—ã.")
        return False
    gemini_utils.log_success(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(st.session_state.generated_incorrect_responses)} '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö' –æ—Ç–≤–µ—Ç–æ–≤.")
    return True

def evaluate_all_responses_logic(user_prompt: str, model_a_response: str) -> bool:
    st.session_state.evaluation_result_id = None
    st.session_state.evaluation_rationale = "" # –°–±—Ä–æ—Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
    st.session_state.all_responses_for_evaluation = {}

    all_responses_dict = {prompts.MODEL_A_ANSWER_ID: model_a_response}
    for i, resp_text in enumerate(st.session_state.generated_incorrect_responses):
        all_responses_dict[prompts.get_incorrect_answer_id(i)] = resp_text
    st.session_state.all_responses_for_evaluation = all_responses_dict

    text_block_for_prompt = ""
    for identifier, text in all_responses_dict.items():
        text_block_for_prompt += f"{identifier}:\n{text}\n---\n"
    
    prompt_text = prompts.get_evaluate_responses_prompt(user_prompt, text_block_for_prompt)
    
    full_evaluation_response = gemini_utils.generate_text_from_model(
        prompt_text, model_type="evaluation", # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        files_for_context=st.session_state.processed_gemini_files
    )

    if not full_evaluation_response:
        gemini_utils.log_error("–ù–µ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç –æ—Ü–µ–Ω–æ—á–Ω–æ–π –º–æ–¥–µ–ª–∏.")
        return False
    
    parts = full_evaluation_response.split(prompts.EVALUATION_SECTION_DELIMITER, 1)
    chosen_id_raw = parts[0].strip()
    rationale_text = parts[1].strip() if len(parts) > 1 else ""

    chosen_id = chosen_id_raw.split()[0] if chosen_id_raw else ""

    if chosen_id in all_responses_dict:
        st.session_state.evaluation_result_id = chosen_id
        st.session_state.evaluation_rationale = rationale_text
        gemini_utils.log_success(f"–û—Ü–µ–Ω–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–ª–∞ ID: '{chosen_id}'. –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ.")
        if not rationale_text:
            gemini_utils.log_warning("–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ—Ç –æ—Ü–µ–Ω–æ—á–Ω–æ–π –º–æ–¥–µ–ª–∏ –ø—É—Å—Ç–æ–µ, —Ö–æ—Ç—è ID –≤—ã–±—Ä–∞–Ω.")
    else:
        gemini_utils.log_warning(f"–û—Ü–µ–Ω–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ '{chosen_id_raw}', ID –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω.")
        # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –ø–æ —Ç–µ–∫—Å—Ç—É (–º–µ–Ω–µ–µ –Ω–∞–¥–µ–∂–Ω–æ, –Ω–æ –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)
        found_by_text = False
        for id_key, text_val in all_responses_dict.items():
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ (–¥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è) —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
            if chosen_id_raw.strip() == text_val.strip(): 
                st.session_state.evaluation_result_id = id_key
                st.session_state.evaluation_rationale = rationale_text # –í—Å–µ —Ä–∞–≤–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
                gemini_utils.log_warning(f"ID '{id_key}' –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é —Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç–∞ (–æ–ø–∞—Å–Ω–æ).")
                found_by_text = True
                break
        if not found_by_text:
            st.session_state.evaluation_rationale = full_evaluation_response # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å—å –æ—Ç–≤–µ—Ç –∫–∞–∫ "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ" –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            return False
            
    return True

# --- UI: –ë–æ–∫–æ–≤–∞—è –ü–∞–Ω–µ–ª—å (–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –í–≤–æ–¥) ---
with st.sidebar:
    st.header("‚öñÔ∏è GeminiJudge")
    st.caption("v2.0 - –î–≤—É—Ö–º–æ–¥–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º")

    with st.expander("üîë API –ö–ª—é—á Google AI", expanded=not st.session_state.gemini_configured):
        # ... (–∫–æ–¥ –¥–ª—è API –∫–ª—é—á–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        api_key_val = st.text_input(
            "–í–∞—à API –∫–ª—é—á:", type="password", value=st.session_state.api_key_input, 
            key=f"api_key_field_{st.session_state.app_run_id}", help="–ú–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —á–µ—Ä–µ–∑ GOOGLE_API_KEY –≤ .env"
        )
        if api_key_val != st.session_state.api_key_input:
            st.session_state.api_key_input = api_key_val
            st.session_state.gemini_configured = False 
            gemini_utils.configure_gemini_api()
            st.rerun()
        if st.session_state.gemini_configured: st.success("API –≥–æ—Ç–æ–≤.")
        elif st.session_state.api_key_input: st.error("API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–ª—é—á.")


    st.session_state.uploaded_st_files = st.file_uploader(
        "1. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:", accept_multiple_files=True, key=f"file_uploader_{st.session_state.app_run_id}"
    )
    
    st.session_state.user_prompt_input = st.text_area(
        "2. –í–∞—à –ü—Ä–æ–º–ø—Ç:", value=st.session_state.user_prompt_input, height=100, key=f"user_prompt_area_{st.session_state.app_run_id}"
    )
    st.session_state.model_a_response_input = st.text_area(
        "3. –û—Ç–≤–µ—Ç '–ú–æ–¥–µ–ª–∏ –ê':", value=st.session_state.model_a_response_input, height=100, key=f"model_a_response_area_{st.session_state.app_run_id}"
    )
    st.session_state.num_incorrect_samples_input = st.number_input(
        "4. –ö–æ–ª-–≤–æ '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö' –ø—Ä–∏–º–µ—Ä–æ–≤:", min_value=1, max_value=4, # –ú–∞–∫—Å 4 –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏ UI
        value=st.session_state.num_incorrect_samples_input, step=1, key=f"num_incorrect_{st.session_state.app_run_id}"
    )

    run_button_disabled = not st.session_state.gemini_configured or \
                          not st.session_state.user_prompt_input.strip() or \
                          not st.session_state.model_a_response_input.strip()

    if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –û—Ü–µ–Ω–∫—É", type="primary", use_container_width=True, disabled=run_button_disabled, key=f"run_button_{st.session_state.app_run_id}"):
        st.session_state.app_run_id += 1
        st.session_state.log_messages = [] 
        st.session_state.processing_complete = False
        gemini_utils.log_info("=== –ù–æ–≤—ã–π —Å–µ–∞–Ω—Å GeminiJudge ===")
        # –§–ª–∞–≥ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        st.session_state.processing_initiate = True 
        st.rerun() # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º, —á—Ç–æ–±—ã –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ —É–≤–∏–¥–µ–ª —Ñ–ª–∞–≥

    st.divider()
    st.subheader("–ñ—É—Ä–Ω–∞–ª –æ–ø–µ—Ä–∞—Ü–∏–π")
    # ... (–∫–æ–¥ –¥–ª—è –∂—É—Ä–Ω–∞–ª–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    if st.session_state.log_messages:
        for level, message in reversed(st.session_state.log_messages):
            if level == "info": st.sidebar.info(message)
            elif level == "success": st.sidebar.success(message)
            elif level == "warning": st.sidebar.warning(message)
            elif level == "error": st.sidebar.error(message)
        if st.sidebar.button("–û—á–∏—Å—Ç–∏—Ç—å –∂—É—Ä–Ω–∞–ª", key=f"clear_log_{st.session_state.app_run_id}", use_container_width=True):
            st.session_state.log_messages = []
            st.rerun()
    else:
        st.sidebar.caption("–ñ—É—Ä–Ω–∞–ª –ø—É—Å—Ç.")


# --- UI: –û—Å–Ω–æ–≤–Ω–∞—è –û–±–ª–∞—Å—Ç—å (–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –°—Ç–∞—Ç—É—Å) ---
st.title("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –û—Ü–µ–Ω–∫–∏ GeminiJudge")

if "processing_initiate" not in st.session_state:
    st.session_state.processing_initiate = False

if st.session_state.processing_initiate:
    overall_success = True
    st.session_state.generated_incorrect_responses = []
    st.session_state.evaluation_result_id = None
    st.session_state.evaluation_rationale = ""
    st.session_state.all_responses_for_evaluation = {}

    with st.status("–≠—Ç–∞–ø 0: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤...", expanded=True) as status_files:
        # ... (–ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        if not handle_file_uploads_and_processing(st.session_state.uploaded_st_files):
            st.error("–ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ–¥–≥–æ—Ç–æ–≤–∫–æ–π —Ñ–∞–π–ª–æ–≤.")
            status_files.update(label="–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤!", state="error", expanded=True)
            overall_success = False
        elif not st.session_state.processed_gemini_files and st.session_state.uploaded_st_files:
             st.warning("–§–∞–π–ª—ã –±—ã–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã, –Ω–æ –Ω–∏ –æ–¥–∏–Ω –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω.")
             status_files.update(label="–§–∞–π–ª—ã –Ω–µ –∞–∫—Ç–∏–≤–Ω—ã!", state="warning", expanded=True)
        else:
            status_files.update(label="–§–∞–π–ª—ã –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã/–ø—Ä–æ–ø—É—â–µ–Ω—ã.", state="complete", expanded=False)


    if overall_success:
        with st.status(f"–≠—Ç–∞–ø 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {st.session_state.num_incorrect_samples_input} '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö' –æ—Ç–≤–µ—Ç–æ–≤ (–º–æ–¥–µ–ª—å: {os.getenv('GEMINI_MODEL_GENERATION', gemini_utils.MODEL_NAME_FOR_GENERATION_DEFAULT)})...", expanded=True) as status_gen:
            # ... (–ª–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
            if not generate_and_parse_incorrect_responses_logic(st.session_state.user_prompt_input, st.session_state.model_a_response_input, st.session_state.num_incorrect_samples_input):
                st.warning("–ü—Ä–æ–±–ª–µ–º–∞ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö' –æ—Ç–≤–µ—Ç–æ–≤.")
                status_gen.update(label="–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö'!", state="warning", expanded=True)
            else:
                status_gen.update(label="'–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ' –æ—Ç–≤–µ—Ç—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã!", state="complete", expanded=False)
    
    if overall_success: 
        with st.status(f"–≠—Ç–∞–ø 2: –û—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ (–º–æ–¥–µ–ª—å: {os.getenv('GEMINI_MODEL_EVALUATION', gemini_utils.MODEL_NAME_FOR_EVALUATION_DEFAULT)})...", expanded=True) as status_eval:
            # ... (–ª–æ–≥–∏–∫–∞ –æ—Ü–µ–Ω–∫–∏ –æ—Ç–≤–µ—Ç–æ–≤ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
            if not evaluate_all_responses_logic(st.session_state.user_prompt_input, st.session_state.model_a_response_input):
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ü–µ–Ω–∫—É –æ—Ç Gemini.")
                status_eval.update(label="–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏!", state="error", expanded=True)
                overall_success = False
            else:
                status_eval.update(label="–û—Ç–≤–µ—Ç—ã –æ—Ü–µ–Ω–µ–Ω—ã!", state="complete", expanded=False)

    
    if overall_success:
        gemini_utils.log_success("=== –°–µ–∞–Ω—Å GeminiJudge –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ! ===")
        st.balloons()
    else:
        gemini_utils.log_error("=== –°–µ–∞–Ω—Å GeminiJudge –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–∞–º–∏/–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏. ===")
    
    st.session_state.processing_complete = True
    st.session_state.processing_initiate = False 
    st.rerun() 

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
if st.session_state.processing_complete:
    if not st.session_state.generated_incorrect_responses and not st.session_state.evaluation_result_id:
        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ—Ü–µ–Ω–∫—É.")

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –°–ù–ê–ß–ê–õ–ê
    if st.session_state.evaluation_result_id:
        st.header("üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –í—ã–±–æ—Ä –∏ –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ—Ç Gemini")
        chosen_id_display = st.session_state.evaluation_result_id
        
        if st.session_state.evaluation_result_id == prompts.MODEL_A_ANSWER_ID:
            st.success(f"**–í—ã–±—Ä–∞–Ω: {chosen_id_display} (–û—Ç–≤–µ—Ç '–ú–æ–¥–µ–ª–∏ –ê')**")
        elif st.session_state.evaluation_result_id.startswith("–ù–ï–ü–†–ê–í–ò–õ–¨–ù–´–ô_–û–¢–íET_"):
            st.warning(f"**–í—ã–±—Ä–∞–Ω: {chosen_id_display} (–û–¥–∏–Ω –∏–∑ '–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö' –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤!)**")
        else: 
            st.info(f"**–í—ã–±—Ä–∞–Ω: {chosen_id_display}**")

        chosen_text = st.session_state.all_responses_for_evaluation.get(st.session_state.evaluation_result_id)
        if chosen_text:
            with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—Å—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞", expanded=False):
                st.markdown(chosen_text)
        
        if st.session_state.evaluation_rationale:
            st.subheader("üìù –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –í—ã–±–æ—Ä–∞:")
            with st.container(border=True):
                st.markdown(st.session_state.evaluation_rationale)
        else:
            st.caption("–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –Ω–µ –±—ã–ª–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å.")
        st.divider()

    # –ó–∞—Ç–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤ (–≤–∫–ª—é—á–∞—è "–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ")
    if st.session_state.all_responses_for_evaluation:
        st.header("üóÇÔ∏è –í—Å–µ –†–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ –û—Ç–≤–µ—Ç—ã")
        
        # –û—Ç–≤–µ—Ç –ú–æ–¥–µ–ª–∏ –ê
        with st.expander(f"–û—Ç–≤–µ—Ç '–ú–æ–¥–µ–ª–∏ –ê' ({prompts.MODEL_A_ANSWER_ID})", expanded=False):
            st.markdown(st.session_state.all_responses_for_evaluation.get(prompts.MODEL_A_ANSWER_ID, "–¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"))

        # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ "–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ" –æ—Ç–≤–µ—Ç—ã
        if st.session_state.generated_incorrect_responses:
            st.subheader("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ '–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ' –û—Ç–≤–µ—Ç—ã:")
            num_cols = min(len(st.session_state.generated_incorrect_responses), 3) # –ú–∞–∫—Å–∏–º—É–º 3 –∫–æ–ª–æ–Ω–∫–∏
            cols_incorrect = st.columns(num_cols) 
            
            for i, resp_text in enumerate(st.session_state.generated_incorrect_responses):
                with cols_incorrect[i % num_cols]:
                    incorrect_id = prompts.get_incorrect_answer_id(i)
                    exp_title = f"–ü–ª–æ—Ö–æ–π –æ—Ç–≤–µ—Ç #{i + 1}"
                    # –ù–µ –≤—ã–¥–µ–ª—è–µ–º –∑–¥–µ—Å—å, —Ç.–∫. –æ—Å–Ω–æ–≤–Ω–æ–π –≤—ã–±–æ—Ä —É–∂–µ –ø–æ–∫–∞–∑–∞–Ω –≤—ã—à–µ
                    # is_chosen = st.session_state.evaluation_result_id == incorrect_id 
                    # if is_chosen: exp_title = f"‚úîÔ∏è {exp_title} (–í—ã–±—Ä–∞–Ω)"
                    
                    with st.container(border=True, height=250): # –û–≥—Ä–∞–Ω–∏—á–∏–º –≤—ã—Å–æ—Ç—É –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏
                        st.markdown(f"**{exp_title} ({incorrect_id})**")
                        st.caption(resp_text)
else:
    if not any(st.session_state.log_messages):
         st.info("–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ —Å–ª–µ–≤–∞ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ—Ü–µ–Ω–∫—É.")